\newcommand{\aadPreviousWorkTable}{%
\begin{table}[h]
    %\large
    \small
    %\footnotesize
    %\scriptsize
    \centering
    \begin{tabular}{lccccc}
        Scheme

        & Space
        
        & \makecell{Public\\parameters}

        & \makecell{Append\\time}

        & \makecell{Lookup\\proof size}

        & \makecell{Append-only\\proof size}\\

        \toprule

        % Note: The space is $n\log{n}$ due to persistency requirement: need to be able to prove append-only property between any two versions i and j and it is unclear how to do so in a lexicographically-ordered tree without using Persistent Authenticated Dictionaries (PADs) which tend to have n\log{n} space, AFAIK.
        Sorted trees~\cite{Ryan2014,coniks}
            & $n\log{n}$  & 1    & $\log{n}$                     & $\log{n}$   & $\red{n}$  \\
        Unsorted trees~\cite{ht,ct}
            & $n$         & 1    & $\log{n}$                     & $\red{n}$   & $\log{n}$  \\
        
        \toprule
        
        \biaad (see \cref{s:aad:from-acc:tall})
            & $\lambda n$ & $4\lambda n$ & $\lambda \log^3{n}$            & $\log^2{n}$ & $\log{n}$  \\

        \rsaaad (see \cref{s:aad:from-acc:tall})
            & $\lambda n$ & 1            & $\lambda \log^3{n}\log\log{n}$ & $\log{n}$   & $\log{n}$  \\
    \end{tabular}
    \caption{
        Asymptotic costs of our accumulator-based constructions versus previous work.
        $n$ is the number of key-value pairs in the dictionary and $\lambda$ is the security parameter.
        Our AAD constructions asymptotically (and concretely) reduce proof sizes but at the cost of higher space on the server, larger public parameters and slower append times.
        Our \biaad construction additionally requires a trusted setup (see  \cref{s:prelim:trusted-setup}).
        As a trade-off, our \biaadset scheme can reduce public parameters to $2\lambda n$ for $\lambda n \log{n}$ space.
    }
    \label{t:aad-comparison} % must go after \caption{} for \cref{} to work
    
\end{table}
}

\aadPreviousWorkTable

Security is often bootstrapped from a \textit{public-key infrastructure (PKI)}.
For example, on the web, \textit{Certificate Authorities (CAs)} digitally sign \textit{certificates} that bind a website to its public key.
This way, a user who successfully verifies the certificate can set up a secure channel with the website.
In general, many systems require a PKI or assume one exists~\cite{frientegrity,LKMS04,mylar,sporc}.
Yet, despite their necessity, PKIs have proven difficult to secure as evidenced by past CA compromises~\cite{mitmgoogle,cahacks,cahacksurvey}.

To address such attacks, \textit{transparency logs}~\cite{ht,ct,ELC16} have been proposed as a way of building \textit{accountable} (and thus more secure) PKIs.
A transparency log is a \textit{dictionary} managed by an untrusted \textit{log server}.
The server periodically appends \textit{key-value pairs} to the dictionary   and is queried by mutually-distrusting \textit{users}, who want to know certain keys' values.
For example, in \textit{key transparency}~\cite{ct,Ryan2014,coniks,aki,arpki,BuldasLaudLipmaa2000,policert,dtki}, CAs are required to publicly log certificates they issue (i.e., values) for each domain (i.e., keys).
Fake certificates can thus be detected in the log and CAs can be held accountable for their misbehavior.

Transparency logging is becoming increasingly important in today's Internet.
This is evident with the widespread deployment of Google's Certificate Transparency (CT)~\cite{ct} project.
Since its initial March 2013 deployment, CT has publicly logged over 2.1 billion certificates~\cite{ct-num-certs}.
Furthermore, since April 2018, Google's Chrome browser requires all new certificates to be published in a CT log~\cite{ct-google-chrome}.
In the same spirit, there has been increased research effort into \textit{software transparency} schemes~\cite{contour,at,chainiac,software-dist-transparency,TD17,STV+16} for securing software updates.
Furthermore, Google is prototyping \textit{general transparency} logs~\cite{ELC16,trillian} via their Trillian project~\cite{trillian}.
Therefore, it is not far-fetched to imagine generalized transparency improving our census system, our elections, and perhaps our government.
But to realize their full potential, transparency logs must operate correctly or be easily caught otherwise.
Specifically:

\paragraph{Logs Should Prove Inclusion.}
Transparency logs are meant to expose rogue CAs who issue fake certificates by allowing impersonated victims to easily find such certificates in the log.
But this only works if users ``enforce'' transparency by only accepting certificates that are provably included in the log.
To convince users, the log should give them an \textit{inclusion proof} that the certificate is in the log.
Otherwise, a rogue CA can simply present the fake certificate directly to the victim user.
This makes detecting impersonation attacks much more difficult, since the impersonated victim will not find the fake certificate in the log.

\paragraph{Logs Should Remain Append-only.}
In a log-based PKI, a devastating attack is still possible: a malicious CA can publish a fake certificate in the log but later collude with the log server to have it removed, which prevents the victim from ever detecting the attack.
Transparency logs should therefore prove that they remain \emph{append-only}, i.e., the new version of the log still contains all entries of the old version.
One trivial way to provide such a proof is to return the newly-added entries to the user and have the user enforce a subset relation.
But this is terribly inefficient.
Ideally, a user with a ``short'' digest $h_{\mathsf{old}}$ should accept a new digest $h_{\mathsf{new}}$ only if it comes with a succinct \emph{append-only proof} computed by the log.
This proof should convince the user that the old log with digest $h_{\mathsf{old}}$ is a subset of the new log with digest $h_{\mathsf{new}}$.

\paragraph{Logs Should Support Lookups.}
When users have access to digests (instead of whole logs), the central question becomes: 
How can a user check \textit{against their digest} which values are registered for a certain key $k$ in the log?
Ideally, a small \emph{lookup proof} should convince the user that the server has returned \textit{nothing more or less than all values} of key $k$.
More formally, the server should \textit{not} be able to equivocate and present one set of values $V$ for $k$ to a user and a different set $V'$ to some other user.
In other words, users who have the same digest should see the same set of values for any key $k$.

\paragraph{Logs Should Remain Fork-Consistent.}
An unavoidable issue is that a malicious log server can also equivocate about digests and \textit{fork} users~\cite{LKMS04,ht}.
For example, at time $i$, the server can append $(k,v)$ to one user's log while appending $(k,v')$ to another user's log.
Since the two users' logs will differ at location $i$, their digests will also differ.
Intuitively, \textit{fork consistency}~\cite{LM07Beyond,LKMS04} guarantees that if two users are given two different digests as above, they must forever be given different digests.
Fork consistency enables users to \textit{gossip}~\cite{CSP+15,STV+16,TD17,DPV+18} and detect forks by checking if they are seeing different digests.

\paragraph{Challenges.}
Building transparency logs with succinct lookup and append-only proofs is a long-standing open problem.
At first glance, a Merkle-based~\cite{merkle} solution seems possible.
Unfortunately, it appears very difficult to organize a Merkle tree so as to support both succinct append-only proofs and succinct lookup proofs.
On one hand, trees with chronologically-ordered leaves~\cite{versum,ht,append-only-skiplists} support logarithmic-sized append-only proofs but at the cost of linear-sized lookup proofs.
On the other hand, trees can be lexicographically-ordered by key~\cite{pads,ad,apad-oprea,BuldasLaudLipmaa2000} to support succinct lookup proofs at the cost of linear append-only proofs (see \cref{s:eval:comparison-to-merkle}).

It might seem natural to combine the two and obtain succinct lookup proofs via the lexicographic tree and succinct append-only proofs via the chronologic tree~\cite{Ryan2014}.
But this does not work either, since there must be a succinct proof that the two trees ``correspond'': they are correctly built over the same set of key-value pairs.
While previous transparency logs~\cite{Ryan2014,dtki} work around this by having users ``collectively'' verify that the two trees correspond~\cite{Ryan2014,dtki,vkd}, this requires a sufficiently high number of honest users and can result in slow detection.
An alternative, which we discuss in \cref{s:snarks}, is to use SNARKs~\cite{qsp,groth16} but this is expensive.

At second glance, \textit{cryptographic accumulators}~\cite{acc-rsa,Nguyen05} seem useful for building transparency logs (see \cref{s:prelim:polycommit}).
Unfortunately, accumulators are asymptotically-inefficient, requiring quadratic time to compute all proofs or to update all proofs after a change to the set.
As a result, a computationally-efficient accumulator-based solution is not obvious.

\paragraph{Our Contribution.}
We introduce a novel cryptographic primitive called an \textit{append-only authenticated dictionary (AAD)} that captures the functionality of a secure transparency log.
Put simply, an AAD maps a key to one or more values in an append-only fashion.
We are the first to give security definitions for AADs.
We are also the first to instantiate asymptotically \textit{efficient} AADs from \textit{bilinear accumulators}~\cite{Nguyen05} and \textit{RSA accumulators} (see \cref{s:aad:from-acc}).
Importantly, our design does not rely on collective verification by users nor on trusted third parties, assuming only an untrusted log server.
Our AAD offers logarithmic-sized append-only proofs, logarithmic-sized lookup proofs and polylogarithmic worst-case time appends (see \cref{t:aad-comparison}).

We implement one of our AAD constructions based on bilinear accumulators in C++ and evaluate it.
Our lookup and append-only proofs are in the order of tens of KiBs and our verification time is in the order of seconds.
For example, a proof for a key with 32 values in a dictionary of $10^6$ entries is 94 KiB and verifies in 2.5 seconds.
While our lookup proof sizes are larger than in previous work, our small-sized append-only proofs can help significantly reduce the overall communication in transparency logs, as we show in \cref{s:eval:worth-it}.
Our code is available at:
\begin{center}
    \url{https://github.com/alinush/libaad-ccs2019}
\end{center}


\section{Overview of Techniques}
\label{s:intro:overview-techniques}
We first build an efficient \textit{append-only authenticated set} (AAS), instead of an AAD.
An AAS is an append-only set of elements with proofs of (non)membership of any element.
%If we let elements be revoked certificates, then an AAS efficiently implements a Revocation Transparency (RT) log~\cite{Laurie15}.
In other words, an AAS is just a universal accumulator~\cite{LLX07} with subset witnesses~\cite{PTT11} that additionally offers fork consistency.
The challenge, however, is to support fast appends while precomputing all proofs.
We overcome this challenge and give AAS constructions from bilinear accumulators (see \cref{s:prelim:bilinear-acc}) and RSA accumulators (see \cref{s:prelim:rsa-acc}).

However, to efficiently implement \textit{any} transparency log, we must modify our AAS into an AAD, which is more ``expressive.''
Specifically, an AAD can provably return all values of a key, while an AAS can only prove that an element is or is not in the set.
In \cref{s:aad}, we describe two techniques to change our AAS into an AAD.
Our two techniques trade off space on the server for faster append times and less public parameters.

\paragraph{AAS From Bilinear Accumulators.}
As explained above, a bilinear accumulator almost fully implements an AAS.
However, bilinear accumulators are computationally-expensive.
Specifically, updating the set and computing a single (non)membership witness takes time linear in $n$, the size of the set.
Thus, computing all $n$ membership witnesses in a bilinear accumulator would take $\Theta(n^2)$, which is prohibitive.
Our work reduces these times to polylogarithmic, but at the cost of increasing witness size from constant to $O(\log^2{n})$.

First, we introduce \textit{\communionTrees} (CTs), a hierarchical way to precompute all membership witnesses in a bilinear accumulator in $\Theta(n\log^2{n})$ time (instead of $O(n^2)$).
Second, instead of ``accumulating'' the elements directly, we build a ``sparse'' prefix tree (or trie) over all elements and accumulate the tree itself.
Then, we precompute non-membership witnesses for all prefixes at the \textit{frontier} of this tree (see \cref{f:accumulated-tree}) in quasilinear time.
As a result, non-membership of an element is reduced to non-membership of one of its prefixes.
(This frontier technique was originally proposed in \cite{zks}.)
Finally, we use classic amortization techniques~\cite{overmars,overmars-van-leeuwen} to append in polylogarithmic time and to precompute append-only proofs between any version $i$ and $j$ of the set.

\paragraph{AAS From RSA Accumulators.}
By replacing the bilinear accumulator with an RSA accumulator in our bilinear-based AAS, we can obtain an RSA-based AAS.
However, for this to work, we must first enhance RSA accumulators with \textit{subset witnesses} and \textit{disjointness witnesses} (see \cref{s:aas:from-rsa-acc:rsa-acc-enhance}).
The RSA-based AAS has a few advantages over the bilinear-based one.
First, all constant-sized membership witnesses in an RSA accumulator can be computed in $\Theta(n\log{n})$ time (see \cref{s:prelim:rsa-acc}).
This asymptotically reduces our AAS (and AAD) proof sizes.
Second, RSA accumulators have constant-sized public parameters.
This reduces storage and memory on the server.

\paragraph{Limitations.}
We only implemented one of our bilinear-based AADs called \biaad (see \cref{s:aad:from-acc:tall}), since group operations are faster in bilinear groups than in RSA groups.
A key limitation is that \biaad has high append times (i.e., a few seconds per append) and high memory usage (i.e., hundreds of GiBs for an AAD of size $2^{20}$).
However, we discuss how to improve it in \cref{s:eval:append-time,s:eval:memory,s:future-work:aads}.

Another limitation is that \biaad security relies on the $q$-PKE ``knowledge'' assumption (commonly used in SNARKs~\cite{groth10,GentryWichs2011}).
Hence, we need a large set of public parameters that must be generated via a \textit{trusted setup} phase, which complicates deployment.
We discussed how this trusted setup can be decentralized in \cref{s:prelim:trusted-setup}.
Our RSA-based construction is proven secure in the generic group model in hidden-order groups~\cite{DK02} but only requires constant-sized parameters, which must also be generated via a trusted setup (see \cref{s:prelim:trusted-setup-rsa}).
